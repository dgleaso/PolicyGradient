# Vanilla Policy Gradient 

This is my implementation of the Vanilla Policy Gradient algorithm from scratch using Numpy.

It runs on the OpenAi gym environment, CartPole-v0, with a discrete action space.

![Running training reward](https://github.com/dgleaso/PolicyGradient/blob/main/running_average_training_reward.png)

Above is a running average of the episode rewards during training.  Training is stopped once this running average exceeds 195.
